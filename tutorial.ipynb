{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain RAG with ChromaDB - Interactive Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the ChromaDB RAG system interactively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from rag_chromadb import ChromaDBRAG\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check if API key is set\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"⚠️  Warning: OPENAI_API_KEY not found. Please set it in .env file\")\n",
    "else:\n",
    "    print(\"✅ OpenAI API key found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize the RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChromaDB RAG\n",
    "rag = ChromaDBRAG(\n",
    "    persist_directory=\"./notebook_chroma_db\",\n",
    "    collection_name=\"notebook_collection\"\n",
    ")\n",
    "print(\"RAG system initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Process Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents from sample_documents directory\n",
    "documents = rag.load_documents(\"./sample_documents\", glob_pattern=\"**/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents into chunks\n",
    "chunks = rag.split_documents(documents, chunk_size=500, chunk_overlap=50)\n",
    "print(f\"Total chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and persist the vector store\n",
    "rag.create_vectorstore(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Similarity Search\n",
    "\n",
    "Let's search for documents similar to a query without using the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform similarity search\n",
    "query = \"What is machine learning?\"\n",
    "results = rag.similarity_search(query, k=3)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"--- Result {i} ---\")\n",
    "    print(doc.page_content[:300] + \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Set Up Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the QA chain\n",
    "rag.setup_qa_chain(llm_model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Ask Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = \"What is artificial intelligence?\"\n",
    "response = rag.query(question)\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(f\"Answer: {response['result']}\\n\")\n",
    "print(f\"Sources: {len(response['source_documents'])} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try more questions\n",
    "questions = [\n",
    "    \"What are the types of machine learning?\",\n",
    "    \"What is deep learning?\",\n",
    "    \"What are neural networks used for?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Q: {q}\")\n",
    "    response = rag.query(q)\n",
    "    print(f\"A: {response['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: View Source Documents\n",
    "\n",
    "Let's see what documents were used to generate the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Explain supervised learning\"\n",
    "response = rag.query(question)\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(f\"Answer: {response['result']}\\n\")\n",
    "print(\"\\nSource Documents:\")\n",
    "for i, doc in enumerate(response['source_documents'], 1):\n",
    "    print(f\"\\n--- Source {i} ---\")\n",
    "    print(doc.page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Using Custom Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = \"\"\"You are a helpful AI teacher. Use the following context to answer the question.\n",
    "If you don't know the answer, say so clearly. Provide a simple explanation suitable for beginners.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "question = \"What is a neural network?\"\n",
    "response = rag.query_with_custom_prompt(question, custom_prompt)\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(f\"Answer: {response['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Loading Existing Vector Store\n",
    "\n",
    "If you've already created a vector store, you can load it instead of creating a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new RAG instance\n",
    "rag_reload = ChromaDBRAG(persist_directory=\"./notebook_chroma_db\")\n",
    "\n",
    "# Load the existing vector store\n",
    "rag_reload.load_vectorstore()\n",
    "\n",
    "# Set up QA chain\n",
    "rag_reload.setup_qa_chain()\n",
    "\n",
    "# Query immediately\n",
    "response = rag_reload.query(\"What are the applications of AI?\")\n",
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment on Your Own!\n",
    "\n",
    "Try asking your own questions or loading your own documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experiments here\n",
    "my_question = \"Your question here\"\n",
    "response = rag.query(my_question)\n",
    "print(response['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
