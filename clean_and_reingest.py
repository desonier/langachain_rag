#!/usr/bin/env python3

import os
import shutil
from ingest_pipeline import ResumeIngestPipeline

def clean_and_reingest():
    """Clean database and re-ingest all files from data directory with proper names"""
    
    print("ğŸ”§ Cleaning Database and Re-ingesting Files")
    print("=" * 50)
    
    # Check what files exist in data directory
    data_dir = "./data/"
    if not os.path.exists(data_dir):
        print(f"âŒ Data directory {data_dir} not found!")
        return
    
    files = [f for f in os.listdir(data_dir) if f.endswith(('.pdf', '.docx'))]
    
    if not files:
        print(f"âŒ No resume files found in {data_dir}")
        return
    
    print(f"ğŸ“ Found {len(files)} files in {data_dir}:")
    for file in files:
        print(f"  â€¢ {file}")
    
    # Ask user for confirmation
    response = input(f"\nâ“ This will delete the current database and re-ingest all {len(files)} files. Continue? (y/N): ")
    
    if response.lower() != 'y':
        print("â„¹ï¸ Operation cancelled")
        return
    
    # Remove existing database
    db_path = "./resume_vectordb"
    if os.path.exists(db_path):
        print(f"ğŸ—‘ï¸ Removing existing database at {db_path}...")
        shutil.rmtree(db_path)
        print("âœ… Database removed")
    
    # Initialize new pipeline
    print("ğŸš€ Initializing new ingest pipeline...")
    ingest_pipeline = ResumeIngestPipeline(enable_llm_parsing=True)
    
    # Ingest each file with proper naming
    print("ğŸ“„ Processing files...")
    total_chunks = 0
    successful_files = 0
    
    for file in files:
        file_path = os.path.join(data_dir, file)
        print(f"\n  ğŸ“„ Processing {file}...")
        
        try:
            # Use the file path directly - this ensures proper naming
            success, resume_id, chunk_count = ingest_pipeline.add_resume(
                file_path,
                force_update=False,
                original_filename=file_path  # This will ensure proper display name
            )
            
            if success:
                total_chunks += chunk_count
                successful_files += 1
                print(f"    âœ… Added {chunk_count} chunks (ID: {resume_id})")
            else:
                print(f"    âŒ Failed to process")
        except Exception as e:
            print(f"    âŒ Error: {e}")
    
    print(f"\n" + "=" * 50)
    print("ğŸ“Š INGESTION COMPLETE:")
    print(f"âœ… Successfully processed: {successful_files}/{len(files)} files")
    print(f"ğŸ“ Total chunks created: {total_chunks}")
    print("ğŸ¯ All files should now have proper './data/filename.ext' paths!")

if __name__ == "__main__":
    clean_and_reingest()